#--------------------------------------------------------------------#
# -- INPUT/ OUTPUT
faunus.graph.input.format=org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat
faunus.input.location=/projects/lgst-new/29/undirected


# output data (graph or statistic) parameters
faunus.graph.output.format=com.thinkaurelius.faunus.formats.titan.hbase.TitanHBaseOutputFormat

#-- for intermediate files only (no side effects in these jobs)
faunus.output.location=/projects/lgst/temp/output
faunus.output.location.overwrite=true

#-- HBASE
faunus.graph.output.titan.storage.backend=hbase
faunus.graph.output.titan.storage.hostname=localhost
faunus.graph.output.titan.storage.port=2181
faunus.graph.output.titan.storage.tablename=kkr2-titan

#-- BATCH LOADING
faunus.graph.output.titan.storage.batch-loading=true
#-- These are set based on https://github.com/thinkaurelius/titan/wiki/Bulk-Loading
#--- Our HBASE instance under load seems to renew in about 6 seconds in a lot of cases -- seems slow.
faunus.graph.output.titan.ids.block-size=10000
faunus.graph.output.titan.storage.idauthority-wait-time=7000
faunus.graph.output.titan.storage.idauthority-retries = 3
faunus.graph.output.titan.storage.ids.renew-timeout = 65000
storage.buffer-size=5000
faunus.graph.output.titan.ids.partition=true
faunus.graph.output.titan.ids.num-partitions=48

#-- Subcluster features
faunus.graph.output.titan.storage.idauthority-unique-bits = 8
faunus.graph.output.titan.storage.idauthority-uniqueid-random = true
#faunus.graph.output.titan.storage.idauthority-local-consistency = true

#-----------------------------------------------------------------------------#
#---------------- Lab41 specific Features ----------------
lab41.hbase.presplit = true
lab41.hbase.numberOfSplits = 240



#------------------------------------------------------------------------------#
#Basic Mapreduce Cofigurations

#-- Handles the Map Side Merge /Output
io.sort.factor=64
io.sort.record.percent=0.15
io.sort.spill.percent=0.98
io.sort.mb=1024

# -- Handles the Reduce side Input
mapred.job.reduce.input.buffer.percent=0.8
mapred.inmem.merge.threshold=0
mapred.job.shuffle.merge.percent = 0.9
# ---- controls size of transaction (does it?)
mapred.max.split.size=134217728

# -- Turn off slow start - can end up utlizing all the memory on a cluster
mapred.reduce.slowstart.completed.maps=1.0
mapred.reduce.tasks=1000

# -- Basic memory and Debug settings
mapred.map.child.java.opts=-Xmx2G -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
mapred.reduce.child.java.opts=-Xmx4G -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
mapred.job.reuse.jvm.num.tasks=-1

# -- Compress both intermediate outputs and final
mapred.output.compress=true
mapred.compress.map.output=true
