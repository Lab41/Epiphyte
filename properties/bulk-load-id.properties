#
# Copyright 2014 In-Q-Tel Inc.
#
#    Licensed under the Apache License, Version 2.0 (the "License");
#    you may not use this file except in compliance with the License.
#    You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS,
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    See the License for the specific language governing permissions and
#    limitations under the License.
#

#--------------------------------------------------------------------#
# -- INPUT/ OUTPUT
faunus.graph.input.format=org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat
faunus.graph.output.format=com.thinkaurelius.faunus.formats.titan.hbase.TitanHBaseOutputFormat

# --
# - faunus.input.location - set in systems.properties
# - faunus.output.location - set in systems. properties
# - faunus.output.location.overwrite - set in systems.properties

#-- HBASE
faunus.graph.output.titan.storage.backend=hbase

# Set hbase hostname,port,tablename in systems.properties file
#faunus.graph.output.titan.storage.short-cf-names=true

#-- BATCH LOADING
faunus.graph.output.titan.storage.batch-loading=true
faunus.graph.output.titan.autotype = none
faunus.graph.output.titan.set-vertex-id=true

faunus.graph.output.titan.ids.flush = true

faunus.graph.output.titan.ids.block-size=250000
faunus.graph.output.titan.storage.idauthority-wait-time= 1000
faunus.graph.output.titan.storage.idauthority-retries = 100

faunus.graph.output.titan.ids.renew-timeout = 200000
faunus.graph.output.titan.ids.partition=true
faunus.graph.output.titan.ids.num-partitions=32
faunus.group.outout.titan.storage.storage.buffer-size=100000

# --- Unclear if the caching will help



#-------------------Metrics ---------------------------
faunus.graph.output.titan.storage.enable-basic-metrics = true

# Required; IP or hostname string
faunus.graph.output.titan.metrics.ganglia.addressing-mode = unicast
faunus.graph.output.titan.metrics.ganglia.hostname = localhost

# Required; specify logging interval in milliseconds
faunus.graph.output.titan.metrics.ganglia.interval = 10000
# Optional
faunus.graph.output.titan.metrics.ganglia.spoof = 10.0.0.1:titan.io

#-----------------------------------------------------------------------------#
#---------------- Lab41 specific Features ----------------
org.lab41.hbase.presplit= true
org.lab41.hbase.preSplitterClass = org.lab41.hbase.TitanHbaseEquiSplitter
org.lab41.hbase.numberOfSplits = 320

#MaximumVertexID
org.lab41.hbase.maxId = 268435456

#Number of vertices per regions
org.lab41.hbase.regionSize = 1048576

#between split
org.lab41.hbase.betweenSplit = true
#------------------------------------------------------------------------------#
#Basic Mapreduce Cofigurations
mapred.map.tasks.speculative.execution=false
mapred.reduce.tasks.speculative.execution=false

#-- Handles the Map Side Merge /Output
io.sort.factor=64
io.sort.record.percent=0.15
io.sort.spill.percent=0.98
io.sort.mb=512

# -- Handles the Reduce side Input
mapred.job.reduce.input.buffer.percent=0.8
mapred.inmem.merge.threshold=0
mapred.job.shuffle.merge.percent = 0.9

# ---- controls size of transaction (does it?)
mapred.max.split.size=67108864

mapred.reduce.slowstart.completed.maps=0.50

# -- Basic memory and Debug settings
mapred.map.child.java.opts=-Xmx1536m -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
mapred.reduce.child.java.opts=-Xmx1536m -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
mapred.job.reuse.jvm.num.tasks= 5


# -- Compress both intermediate outputs and final
mapred.output.compress=true
mapred.compress.map.output=true


#increasing the number of failures
mapred.max.tracker.failures = 20
mapred.map.max.attempts = 20

#Settings the hbase time out to accomodate table splits
hbase.rpc.timeout=240000

# Settings mapred time out to accomodate table split
mapred.task.timeout = 1200000

# -- Capacity Scheduler settings
# -- Need to set the max memory to be more than the heap size
# -- since we are using 1G slots for maps - requested 2 slots
# -- Since we are using 2G slots for reduces - requested 1 slots
mapred.job.map.memory.mb = 2048
mapred.job.reduce.memory.mb = 2048
